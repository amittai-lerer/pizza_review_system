
---
title: Pizza Review RAG
emoji: ğŸ•
colorFrom: red
colorTo: yellow
sdk: streamlit
app_file: app.py
pinned: false
---

# ğŸ• Pizza Review RAG â€“ AI-Powered Pizza Discovery for Israel

A sophisticated Natural Language Processing (NLP) system that leverages Large Language Models (LLMs), vector embeddings, and semantic search to provide intelligent analysis of Israeli pizza restaurant reviews. Built with production-grade engineering practices and a clean, modular architecture.

---

## ğŸ“Š Project Highlights

* ğŸ”„ **LLM Switching**: Use either a **local model** (`llama3` via Ollama) or a **cloud model** (Together AI)
* ğŸ§  **Prompt Rewriting**: Refines user queries to improve search and answer quality
* ğŸ—œï¸ **City Extraction**: Converts slang or abbreviations like `TLV` â†’ `Tel Aviv`
* ğŸ” **Vector Search**: Uses ChromaDB with Hugging Face embeddings for fast semantic retrieval
* ğŸ–¥ï¸ **Modern UI**: Streamlit frontend with logging, query results, and LLM controls
* ğŸ³ **Docker Support**: Easy to containerize for deployment or portability

---

## ğŸ” Technologies Used

| Layer      | Tool / Lib                                                                      |
| ---------- | ------------------------------------------------------------------------------- |
| LLM        | [Ollama](https://ollama.com), [Together AI](https://www.together.ai), LangChain |
| Vector DB  | [ChromaDB](https://www.trychroma.com)                                           |
| Embeddings | [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5)         |
| UI         | [Streamlit](https://streamlit.io)                                               |
| Logging    | Python built-in logging module                                                  |
| Container  | Docker, Docker Compose                                                          |

---

## ğŸ“ Folder Structure

```
pizza_review_system/
â”œâ”€â”€ app.py              # Streamlit interface
â”œâ”€â”€ core.py             # Prompt logic, LLM calls, city extraction
â”œâ”€â”€ vector.py           # Vector store loading & query interface
â”œâ”€â”€ logger_config.py    # Logging config shared across modules
â”œâ”€â”€ data/               # Contains review CSV file
â”œâ”€â”€ logs/               # Output logs (app.log, vector.log, etc.)
â”œâ”€â”€ .streamlit/         # Streamlit config + secrets.toml (ignored by Git)
â”œâ”€â”€ Dockerfile          # Container build instructions
â”œâ”€â”€ docker-compose.yml  # Optional container orchestrator
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md           # You're here.
```

---

## ğŸ’ª Key Features

### âœ… Smart LLM Prompting

* Rewrites vague or casual input into semantically structured review prompts
* Example: `pizza in JLM?` â†’ `I had great pizza in Jerusalem.`

### âœ… Semantic Retrieval

* Filters reviews by city and similarity
* Uses BAAI embeddings and ChromaDB for scalable local vector search

### âœ… Flexible LLM Execution

* Use `llama3` locally via Ollama (no API cost)
* Or query Together AI's `Llama-3.3-70B-Instruct-Turbo-Free` in the cloud

### âœ… Rich Logging

* Tracks rewrite steps, LLM calls, parsed results, and user queries
* Logs to both file (`logs/app.log`) and console

## ğŸš€ Setup Instructions

### 1. Clone & Install

```bash
git clone https://github.com/amittai-lerer/pizza_review_system.git
cd pizza_review_system
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

### 2. ğŸ” Add Secrets for Cloud Model (Optional)

To use the Together AI model, create a file:

```bash
mkdir -p .streamlit
nano .streamlit/secrets.toml
```

Add your API key:

```toml
TOGETHER_API_KEY = "your-together-api-key"
```

> âš ï¸ This file is excluded from version control by `.gitignore`

---

### 3. ğŸ§  Run Ollama Locally (Optional)

```bash
ollama pull llama3
ollama run llama3
```

---

### 4. ğŸš€ Launch the App

```bash
streamlit run app.py
```

Then open your browser at: [http://localhost:8501](http://localhost:8501)

---

## ğŸ’¬ Example Queries

```text
Best pizza in TLV?
Spiciest toppings in Haifa?
Authentic Neapolitan pizza in JLM?
Where to find gluten-free pizza in Holon?
Top-rated places for pizza crust?
```

---

## ğŸ§ª Cloud Model Integration (Optional)

* Ensure `TOGETHER_API_KEY` is set in `.streamlit/secrets.toml`
* The app automatically switches to Together AI when enabled via the UI toggle
* Default model:

```text
meta-llama/Llama-3.3-70B-Instruct-Turbo-Free
```

---

## ğŸ³ Docker Support (Optional)

**Build and run the app in a container:**

```bash
docker build -t pizza-review .
docker run -p 8501:8501 pizza-review
```

**Or use Docker Compose:**

```bash
docker-compose up
```

---

## ğŸ“œ License

MIT License â€” Freely usable for educational, demo, or portfolio purposes.

---
