# ğŸ• Pizza Review RAG â€” Intelligent Pizza Discovery with LLMs & Vector Search

This project is a modular, production-grade Retrieval-Augmented Generation (RAG) system for intelligent pizza recommendations, combining Large Language Models (LLMs) with semantic vector search. It features a FastAPI backend and a Streamlit frontend, leveraging LangChain for orchestration, ChromaDB for vector retrieval, and Hugging Face embeddings for similarity scoring. The system includes components for query rewriting, city extraction, and context-aware answer generation using local (Ollama) or cloud-based (Together AI) models. Built to demonstrate scalable and maintainable AI engineering practices, the architecture provides a clear blueprint for real-world applications of LLMs in structured information retrieval.


---

## ğŸ“Š Project Highlights

* ğŸ”„ **LLM Switching**: Use either a **local model** (`llama3` via Ollama) or a **cloud model** (Together AI)
* ğŸ§  **Prompt Rewriting**: Refines user queries to improve search and answer quality
* ğŸ–œï¸ **City Extraction**: Converts slang or abbreviations like `TLV` â†’ `Tel Aviv`
* ğŸ” **Vector Search**: Uses ChromaDB with Hugging Face embeddings for fast semantic retrieval
* ğŸ–¥ï¸ **Modern UI**: Streamlit frontend with FastAPI backend
* ğŸƒ **Clean Backend API**: Modular FastAPI server for scalability and production-readiness
* ğŸ³ **Docker Support**: Easy to containerize for deployment or portability

---

## ğŸ” Technologies Used

| Layer      | Tool / Lib                                                                      |
| ---------- | ------------------------------------------------------------------------------- |
| LLM        | [Ollama](https://ollama.com), [Together AI](https://www.together.ai), LangChain |
| Vector DB  | [ChromaDB](https://www.trychroma.com)                                           |
| Embeddings | [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5)         |
| Backend    | [FastAPI](https://fastapi.tiangolo.com)                                         |
| Frontend   | [Streamlit](https://streamlit.io)                                               |
| Logging    | Python built-in logging module                                                  |
| Container  | Docker, Docker Compose                                                          |

---

## ğŸ“ Folder Structure

```bash
pizza_review_system/
â”œâ”€â”€ app.py              # Streamlit interface
â”œâ”€â”€ main.py             # FastAPI backend entrypoint
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py          # FastAPI route handler
â”‚   â”œâ”€â”€ core.py         # Prompt logic, LLM calls, city extraction
â”‚   â”œâ”€â”€ vector.py       # Vector store loading & query interface
â”‚   â””â”€â”€ logger_config.py# Logging config
â”œâ”€â”€ data/               # Contains review CSV file
â”œâ”€â”€ logs/               # Output logs (app.log, vector.log, etc.)
â”œâ”€â”€ .streamlit/         # Streamlit config + secrets.toml (ignored by Git)
â”œâ”€â”€ Dockerfile          # Container build instructions
â”œâ”€â”€ docker-compose.yml  # Optional container orchestrator
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md           # You're here.
```

---

## ğŸ’ª Key Features

### âœ… LLM Query Rewriting

* Rewrites vague or casual input into semantically structured prompts
* Example: `pizza in JLM?` â†’ `I had great pizza in Jerusalem.`

### âœ… Semantic Retrieval

* Filters reviews by city and meaning
* Uses sentence embeddings and ChromaDB for similarity search

### âœ… Modular RAG Backend (FastAPI)

* `/ask-pizza` endpoint receives questions and returns structured JSON
* Can be consumed by any frontend (Streamlit, React, mobile app, etc.)

### âœ… Frontend (Streamlit)

* Allows toggling between LLMs
* Displays generated answers and source reviews with metadata

### âœ… Logging

* Tracks LLM calls, user queries, vector DB usage
* Logs to file and terminal

---

## ğŸš€ Setup Instructions

### 1. Clone & Install

```bash
git clone https://github.com/amittai-lerer/pizza_review_system.git
cd pizza_review_system
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. ğŸ” Add Secrets for Cloud Model (Optional)

```bash
mkdir -p .streamlit
nano .streamlit/secrets.toml
```

```toml
TOGETHER_API_KEY = "your-together-api-key"
```

### 3. ğŸ§  Run Ollama Model (Optional)

```bash
ollama pull llama3
ollama run llama3
```

### 4. ğŸš€ Launch Backend API

```bash
python main.py
```

This runs the FastAPI server on: [http://localhost:8000](http://localhost:8000)

### 5. ğŸš€ Launch Frontend App

```bash
streamlit run app.py
```

Streamlit will run at: [http://localhost:8501](http://localhost:8501)

---

## ğŸ•µï¸â€â™‚ï¸ Sample Queries

```text
Best pizza in TLV?
Spiciest toppings in Haifa?
Authentic Neapolitan pizza in JLM?
Where to find gluten-free pizza in Holon?
Top-rated places for pizza crust?
```

---

## ğŸ³ Docker Support (Optional)

```bash
docker build -t pizza-review .
docker run -p 8501:8501 pizza-review
```

Or with Docker Compose:

```bash
docker-compose up
```

---

## ğŸ”’ License

MIT License â€” Freely usable for educational, demo, or portfolio purposes.
